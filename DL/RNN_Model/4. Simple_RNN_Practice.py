# ğŸ“Œ ë¬¸ì œ: ê°„ë‹¨í•œ RNN ëª¨ë¸ êµ¬í˜„í•˜ê¸°
# ë‹¤ìŒ ìš”êµ¬ì‚¬í•­ì„ ë§Œì¡±í•˜ëŠ” RNN ëª¨ë¸ì„ ì§ì ‘ ë§Œë“¤ì–´ ë³´ì„¸ìš”.

# ğŸ”¹ ë¬¸ì œ ì„¤ëª…
# ì£¼ì–´ì§„ ì‹œê³„ì—´ ë°ì´í„°ì—ì„œ ì´ì „ 3ê°œ ê°’ì„ ì´ìš©í•´ ë‹¤ìŒ ê°’ì„ ì˜ˆì¸¡í•˜ëŠ” ê°„ë‹¨í•œ RNN ëª¨ë¸ì„ êµ¬í˜„í•˜ì„¸ìš”.

# ğŸ”¹ ìš”êµ¬ì‚¬í•­
# ì…ë ¥ ë°ì´í„°:

# ë¦¬ìŠ¤íŠ¸ data = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100] ë¥¼ ì‚¬ìš©
# window_size=3 ë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµ ë°ì´í„°ë¥¼ ìƒì„±í•  ê²ƒ
# ëª¨ë¸ ì„¤ê³„

# TensorFlowì˜ Sequential ëª¨ë¸ì„ ì‚¬ìš©
# SimpleRNN ì¸µì„ í¬í•¨í•  ê²ƒ
# ì ì ˆí•œ í™œì„±í™” í•¨ìˆ˜ì™€ ì¶œë ¥ì¸µì„ ì„¤ì •í•  ê²ƒ
# ëª¨ë¸ í•™ìŠµ

# epochs=100 ìœ¼ë¡œ ì„¤ì •
# batch_size=1 ë¡œ ì„¤ì •
# ìƒˆë¡œìš´ ì…ë ¥ [70, 80, 90] ì„ ì£¼ì—ˆì„ ë•Œ ì˜ˆì¸¡ê°’ì„ ì¶œë ¥

# ğŸ”¹ ì¶”ê°€ ì¡°ê±´
# train_test_split()ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ì˜ 80%ëŠ” í•™ìŠµ, 20%ëŠ” í…ŒìŠ¤íŠ¸ì— ì‚¬ìš©í•  ê²ƒ
# MinMaxScalerë¥¼ ì´ìš©í•´ ë°ì´í„°ë¥¼ 0~1 ë²”ìœ„ë¡œ ì •ê·œí™”í•  ê²ƒ
# ğŸ”¹ ëª©í‘œ
# ì½”ë“œë¥¼ ì‘ì„±í•˜ì—¬ ëª¨ë¸ì„ í›ˆë ¨í•˜ê³  ì˜ˆì¸¡ê°’ì„ ì¶œë ¥í•˜ì„¸ìš”.
# (ì •ë‹µì´ ë§ëŠ”ì§€ í™•ì¸í•˜ë ¤ë©´ ë‚˜ì¤‘ì— ìš”ì²­í•˜ì„¸ìš”! ğŸ˜‰)

import numpy as np
import tensorflow as tf
from tensorflow import keras
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import SimpleRNN, Dense, Bidirectional, LSTM

train_list = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200]
window_size = 3

def make_data(sequence_data, cut_size):
    x_total_list = []
    y_total_list = []
    for i in range(len(sequence_data)-cut_size+1):
        x_list = []
        y_list = []
        for j in range(cut_size):
            if j < 2:
                x_list.append(sequence_data[i+j])
            else:
                y_total_list.append(sequence_data[i+j])

        x_total_list.append(x_list)
    
    x_total_list = np.asarray(x_total_list) # [[10, 20], [20, 30], [30, 40], ...]
    y_total_list = np.asarray(y_total_list) # [[30], [40], [50], ...]

    return x_total_list, y_total_list


x, y = make_data(train_list, window_size)

# print(x, y)
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=10)

mms_for_x = MinMaxScaler()
mms_for_y = MinMaxScaler()

print(X_train.shape)

y_train = y_train.reshape(-1, 1)
y_test = y_test.reshape(-1, 1)

print(y_train.shape)

scaled_X_train = mms_for_x.fit_transform(X_train)
scaled_X_test = mms_for_x.transform(X_test)
scaled_y_train = mms_for_y.fit_transform(y_train)
scaled_y_test = mms_for_y.transform(y_test)

final_X_train = scaled_X_train.reshape(scaled_X_train.shape[0], scaled_X_train.shape[1], 1)
final_X_test = scaled_X_test.reshape(scaled_X_test.shape[0], scaled_X_test.shape[1], 1)

model = Sequential([
        SimpleRNN(10, activation="relu", return_sequences=True, input_shape=(2, 1)),
        # SimpleRNN(30, activation="tanh", return_sequences=True),
        Bidirectional(LSTM(30, return_sequences=True)),
        SimpleRNN(10, activation="relu"),
        Dense(1)
])

print(model.summary())

model.compile(optimizer="adam", loss="mse")
model.fit(final_X_train, scaled_y_train, epochs=700, validation_split=0.2)

test_input_1 = np.asarray([210, 220])
test_input_1 = test_input_1.reshape(1, -1)

print(test_input_1.shape)

test_input_2 = np.asarray([290, 300])
test_input_2 = test_input_2.reshape(1, -1)

scaled_test_input = mms_for_x.transform(test_input_1)
final_test_input = scaled_test_input.reshape(1, 2, 1)
predicted = model.predict(final_test_input)
answer = mms_for_y.inverse_transform(predicted)
print(f"first predicted: {answer}")

scaled_test_input2 = mms_for_x.transform(test_input_2)
final_test_input2 = scaled_test_input2.reshape(1, 2, 1)
predicted2 = model.predict(final_test_input2)
answer2 = mms_for_y.inverse_transform(predicted2)
print(f"second predicted: {answer2}")